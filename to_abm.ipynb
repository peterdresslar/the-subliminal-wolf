{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialized model_states with 100 sheep and 10 wolves\n",
      "initialized stores with [100] sheep and (len: 1) wolves\n",
      "step 0\n",
      "s: 100\n",
      "agents_w count: 10\n",
      "starting to process wolves\n",
      "dw_total: 1.2000000000000002\n",
      "agents_w: (len: 10)\n",
      "net_agents_w_change: 1\n",
      "accumulated_dw_remainder: 0.20000000000000018\n",
      "agents_w_state updated: (len: 11)\n",
      "reference ODE: s    100.0\n",
      "w     10.0\n",
      "Name: 0, dtype: float64\n",
      "step 1\n",
      "s: 99.96\n",
      "agents_w count: 11\n",
      "starting to process wolves\n",
      "dw_total: 1.3193400000000002\n",
      "agents_w: (len: 11)\n",
      "net_agents_w_change: 1\n",
      "accumulated_dw_remainder: 0.3193400000000002\n",
      "agents_w_state updated: (len: 12)\n",
      "reference ODE: s    99.874909\n",
      "w    11.275624\n",
      "Name: 1, dtype: float64\n",
      "step 2\n",
      "s: 99.71609759999998\n",
      "agents_w count: 12\n",
      "starting to process wolves\n",
      "dw_total: 1.4348897567999999\n",
      "agents_w: (len: 12)\n",
      "net_agents_w_change: 1\n",
      "accumulated_dw_remainder: 0.43488975679999986\n",
      "agents_w_state updated: (len: 13)\n",
      "reference ODE: s    99.480063\n",
      "w    12.709054\n",
      "Name: 2, dtype: float64\n",
      "step 3\n",
      "s: 99.26936948275198\n",
      "agents_w count: 13\n",
      "starting to process wolves\n",
      "dw_total: 1.545752704913664\n",
      "agents_w: (len: 13)\n",
      "net_agents_w_change: 1\n",
      "accumulated_dw_remainder: 0.5457527049136639\n",
      "agents_w_state updated: (len: 14)\n",
      "reference ODE: s    98.786165\n",
      "w    14.313060\n",
      "Name: 3, dtype: float64\n",
      "step 4\n",
      "s: 98.62213319372445\n",
      "agents_w count: 14\n",
      "starting to process wolves\n",
      "dw_total: 1.651064797068213\n",
      "agents_w: (len: 14)\n",
      "net_agents_w_change: 1\n",
      "accumulated_dw_remainder: 0.6510647970682131\n",
      "agents_w_state updated: (len: 15)\n",
      "reference ODE: s    97.764977\n",
      "w    16.098819\n",
      "Name: 4, dtype: float64\n",
      "step 5\n",
      "s: 97.77792773358617\n",
      "agents_w count: 15\n",
      "starting to process wolves\n",
      "dw_total: 1.7500033740056888\n",
      "agents_w: (len: 15)\n",
      "net_agents_w_change: 1\n",
      "accumulated_dw_remainder: 0.7500033740056888\n",
      "agents_w_state updated: (len: 16)\n",
      "reference ODE: s    96.390802\n",
      "w    18.074898\n",
      "Name: 5, dtype: float64\n",
      "step 6\n",
      "s: 96.74148169961016\n",
      "agents_w count: 16\n",
      "starting to process wolves\n",
      "dw_total: 1.8417955607906438\n",
      "agents_w: (len: 16)\n",
      "net_agents_w_change: 1\n",
      "accumulated_dw_remainder: 0.8417955607906438\n",
      "agents_w_state updated: (len: 17)\n",
      "reference ODE: s    94.642267\n",
      "w    20.246061\n",
      "Name: 6, dtype: float64\n",
      "step 7\n",
      "s: 95.51866937092709\n",
      "agents_w count: 17\n",
      "starting to process wolves\n",
      "dw_total: 1.9257260689586402\n",
      "agents_w: (len: 17)\n",
      "net_agents_w_change: 1\n",
      "accumulated_dw_remainder: 0.9257260689586402\n",
      "agents_w_state updated: (len: 18)\n",
      "reference ODE: s    92.504325\n",
      "w    22.611984\n",
      "Name: 7, dtype: float64\n",
      "step 8\n",
      "s: 94.11645530456187\n",
      "agents_w count: 18\n",
      "starting to process wolves\n",
      "dw_total: 2.0011442932231702\n",
      "agents_w: (len: 18)\n",
      "net_agents_w_change: 2\n",
      "accumulated_dw_remainder: 0.001144293223170223\n",
      "agents_w_state updated: (len: 20)\n",
      "reference ODE: s    89.970341\n",
      "w    25.165967\n",
      "Name: 8, dtype: float64\n",
      "step 9\n",
      "s: 92.54282817186959\n",
      "agents_w count: 20\n",
      "starting to process wolves\n",
      "dw_total: 2.1762848451560886\n",
      "agents_w: (len: 20)\n",
      "net_agents_w_change: 2\n",
      "accumulated_dw_remainder: 0.17628484515608855\n",
      "agents_w_state updated: (len: 22)\n",
      "reference ODE: s    87.044075\n",
      "w    27.893806\n",
      "Name: 9, dtype: float64\n",
      "step 10\n",
      "s: 90.6179373458947\n",
      "agents_w count: 22\n",
      "starting to process wolves\n",
      "dw_total: 2.330391932414526\n",
      "agents_w: (len: 22)\n",
      "net_agents_w_change: 2\n",
      "accumulated_dw_remainder: 0.33039193241452613\n",
      "agents_w_state updated: (len: 24)\n",
      "reference ODE: s    83.741277\n",
      "w    30.772993\n",
      "Name: 10, dtype: float64\n",
      "step 20\n",
      "s: 58.19939256671426\n",
      "agents_w count: 42\n",
      "starting to process wolves\n",
      "dw_total: 2.4065617317029964\n",
      "agents_w: (len: 42)\n",
      "net_agents_w_change: 2\n",
      "accumulated_dw_remainder: 0.40656173170299637\n",
      "agents_w_state updated: (len: 44)\n",
      "reference ODE: s    41.057178\n",
      "w    58.522272\n",
      "Name: 20, dtype: float64\n",
      "step 30\n",
      "s: 25.396460389721405\n",
      "agents_w count: 53\n",
      "starting to process wolves\n",
      "dw_total: 0.4290186009828522\n",
      "agents_w: (len: 53)\n",
      "net_agents_w_change: 0\n",
      "accumulated_dw_remainder: 0.4290186009828522\n",
      "agents_w_state updated: (len: 53)\n",
      "reference ODE: s    14.185262\n",
      "w    63.560648\n",
      "Name: 30, dtype: float64\n",
      "step 40\n",
      "s: 10.096017553476644\n",
      "agents_w count: 53\n",
      "starting to process wolves\n",
      "dw_total: -0.7873666044986076\n",
      "agents_w: (len: 53)\n",
      "net_agents_w_change: 0\n",
      "accumulated_dw_remainder: -0.7873666044986076\n",
      "agents_w_state updated: (len: 53)\n",
      "reference ODE: s     5.299610\n",
      "w    53.786639\n",
      "Name: 40, dtype: float64\n",
      "step 50\n",
      "s: 4.149934406761861\n",
      "agents_w count: 47\n",
      "starting to process wolves\n",
      "dw_total: -1.1174296243232897\n",
      "agents_w: (len: 47)\n",
      "net_agents_w_change: -1\n",
      "accumulated_dw_remainder: -0.11742962432328974\n",
      "agents_w_state updated: (len: 46)\n",
      "reference ODE: s     2.483694\n",
      "w    42.074432\n",
      "Name: 50, dtype: float64\n",
      "step 60\n",
      "s: 2.0805027638157374\n",
      "agents_w count: 37\n",
      "starting to process wolves\n",
      "dw_total: -0.994532096608226\n",
      "agents_w: (len: 37)\n",
      "net_agents_w_change: 0\n",
      "accumulated_dw_remainder: -0.994532096608226\n",
      "agents_w_state updated: (len: 37)\n",
      "reference ODE: s     1.449896\n",
      "w    32.056580\n",
      "Name: 60, dtype: float64\n",
      "step 70\n",
      "s: 1.2012841376321046\n",
      "agents_w count: 35\n",
      "starting to process wolves\n",
      "dw_total: -0.9869325827743151\n",
      "agents_w: (len: 35)\n",
      "net_agents_w_change: 0\n",
      "accumulated_dw_remainder: -0.9869325827743151\n",
      "agents_w_state updated: (len: 35)\n",
      "reference ODE: s     1.012309\n",
      "w    24.173393\n",
      "Name: 70, dtype: float64\n",
      "step 80\n",
      "s: 0.7148399254014028\n",
      "agents_w count: 34\n",
      "starting to process wolves\n",
      "dw_total: -0.9835431638045289\n",
      "agents_w: (len: 34)\n",
      "net_agents_w_change: 0\n",
      "accumulated_dw_remainder: -0.9835431638045289\n",
      "agents_w_state updated: (len: 34)\n",
      "reference ODE: s     0.811874\n",
      "w    18.146103\n",
      "Name: 80, dtype: float64\n",
      "step 90\n",
      "s: 0.43089320150564864\n",
      "agents_w count: 34\n",
      "starting to process wolves\n",
      "dw_total: -0.9980244467232124\n",
      "agents_w: (len: 34)\n",
      "net_agents_w_change: 0\n",
      "accumulated_dw_remainder: -0.9980244467232124\n",
      "agents_w_state updated: (len: 34)\n",
      "reference ODE: s     0.723420\n",
      "w    13.593368\n",
      "Name: 90, dtype: float64\n",
      "step 100\n",
      "s: 0.26366181070106226\n",
      "agents_w count: 33\n",
      "starting to process wolves\n",
      "dw_total: -0.976948740370297\n",
      "agents_w: (len: 33)\n",
      "net_agents_w_change: 0\n",
      "accumulated_dw_remainder: -0.976948740370297\n",
      "agents_w_state updated: (len: 33)\n",
      "reference ODE: s     0.697788\n",
      "w    10.174552\n",
      "Name: 100, dtype: float64\n",
      "step 200\n",
      "s: 0.0020689596908769073\n",
      "agents_w count: 33\n",
      "starting to process wolves\n",
      "dw_total: -0.9898975864953012\n",
      "agents_w: (len: 33)\n",
      "net_agents_w_change: 0\n",
      "accumulated_dw_remainder: -0.9898975864953012\n",
      "agents_w_state updated: (len: 33)\n",
      "reference ODE: s    2.646336\n",
      "w    0.612831\n",
      "Name: 200, dtype: float64\n",
      "step 300\n",
      "s: 1.623516955713688e-05\n",
      "agents_w count: 33\n",
      "starting to process wolves\n",
      "dw_total: -0.9899991963591068\n",
      "agents_w: (len: 33)\n",
      "net_agents_w_change: 0\n",
      "accumulated_dw_remainder: -0.9899991963591068\n",
      "agents_w_state updated: (len: 33)\n",
      "reference ODE: s    18.663967\n",
      "w     0.103372\n",
      "Name: 300, dtype: float64\n",
      "step 400\n",
      "s: 1.2739771186033504e-07\n",
      "agents_w count: 33\n",
      "starting to process wolves\n",
      "dw_total: -0.9899999936938135\n",
      "agents_w: (len: 33)\n",
      "net_agents_w_change: 0\n",
      "accumulated_dw_remainder: -0.9899999936938135\n",
      "agents_w_state updated: (len: 33)\n",
      "reference ODE: s    94.010483\n",
      "w    20.971426\n",
      "Name: 400, dtype: float64\n",
      "step 500\n",
      "s: 9.996924842780135e-10\n",
      "agents_w count: 33\n",
      "starting to process wolves\n",
      "dw_total: -0.9899999999505149\n",
      "agents_w: (len: 33)\n",
      "net_agents_w_change: 0\n",
      "accumulated_dw_remainder: -0.9899999999505149\n",
      "agents_w_state updated: (len: 33)\n",
      "reference ODE: s    0.704012\n",
      "w    8.472897\n",
      "Name: 500, dtype: float64\n",
      "step 600\n",
      "s: 7.844607634849535e-12\n",
      "agents_w count: 33\n",
      "starting to process wolves\n",
      "dw_total: -0.9899999999996123\n",
      "agents_w: (len: 33)\n",
      "net_agents_w_change: 0\n",
      "accumulated_dw_remainder: -0.9899999999996123\n",
      "agents_w_state updated: (len: 33)\n",
      "reference ODE: s    2.981611\n",
      "w    0.520655\n",
      "Name: 600, dtype: float64\n",
      "step 700\n",
      "s: 6.15567986281131e-14\n",
      "agents_w count: 33\n",
      "starting to process wolves\n",
      "dw_total: -0.9899999999999971\n",
      "agents_w: (len: 33)\n",
      "net_agents_w_change: 0\n",
      "accumulated_dw_remainder: -0.9899999999999971\n",
      "agents_w_state updated: (len: 33)\n",
      "reference ODE: s    21.151835\n",
      "w     0.103257\n",
      "Name: 700, dtype: float64\n",
      "step 800\n",
      "s: 4.830374741125904e-16\n",
      "agents_w count: 33\n",
      "starting to process wolves\n",
      "dw_total: -0.9900000000000007\n",
      "agents_w: (len: 33)\n",
      "net_agents_w_change: 0\n",
      "accumulated_dw_remainder: -0.9900000000000007\n",
      "agents_w_state updated: (len: 33)\n",
      "reference ODE: s    73.503839\n",
      "w    38.817459\n",
      "Name: 800, dtype: float64\n",
      "step 900\n",
      "s: 3.79040506649271e-18\n",
      "agents_w count: 33\n",
      "starting to process wolves\n",
      "dw_total: -0.9900000000000007\n",
      "agents_w: (len: 33)\n",
      "net_agents_w_change: 0\n",
      "accumulated_dw_remainder: -0.9900000000000007\n",
      "agents_w_state updated: (len: 33)\n",
      "reference ODE: s    0.724391\n",
      "w    7.056723\n",
      "Name: 900, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# subliminal wolf ABM: this time it's personal\n",
    "# v0.1.0\n",
    "\n",
    "# Same setup but with price-sensitive wolves\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.integrate import odeint\n",
    "\n",
    "# throttle\n",
    "throttle = 100\n",
    "\n",
    "# Not converting sheep from the ODE for now\n",
    "model_params = {\n",
    "    'alpha': 1,\n",
    "    'beta': 0.1, # we need this at the model level only for the reference ODE\n",
    "    'gamma': 1.5, # we need this at the model level only for the reference ODE\n",
    "    'delta': .75, # we need this at the model level only for the reference ODE\n",
    "    's_start': 100,\n",
    "    'w_start': 10,\n",
    "    'dt': .02, \n",
    "    # 'eps': 1e-6 # not currently used\n",
    "}\n",
    "\n",
    "model_state = {\n",
    "    'step_accumulated_ds': None,\n",
    "    'step_accumulated_dw': None,\n",
    "    'accumulated_dw_remainder': None, # re-initialize? for now, no.\n",
    "    's_state': None,\n",
    "    'agents_w_state': None\n",
    "}\n",
    "\n",
    "# time params.\n",
    "model_time = {\n",
    "    'tmax': 1000, # \"steps\" or \"ticks\"\n",
    "    'time': None # will be computed from tmax and dt\n",
    "}\n",
    "    \n",
    "#############################################################\n",
    "# Agent Functions\n",
    "#############################################################\n",
    "\n",
    "def instanitate_agent_w(model_params): # note these are model params only due to the ODE reference\n",
    "    # it would be reasonable to even call these \"agent_params\" and name like w_beta. we avoid\n",
    "    # this for now, but it might be a good idea.\n",
    "    return (\n",
    "        model_params['beta'],\n",
    "        model_params['gamma'],\n",
    "        model_params['delta']\n",
    "    )\n",
    "\n",
    "def process_agent_step_w(agent_w, model_params, model_state):\n",
    "    # process_agent_step reads the state of the agent, the state of the model. since this agent is not mutable\n",
    "    # (it probably cannot be if we deterministically migrate from an ODE)\n",
    "    # the agent can only operate on the state of the model.\n",
    "    # as such, this function outputs accumulated changes to s and agents_w in an approach that\n",
    "    # approximates the ODE.\n",
    "\n",
    "    # unpack\n",
    "    dt = model_params['dt']\n",
    "\n",
    "    s = model_state['s_state']\n",
    "    current_step_accumulated_dw = model_state['step_accumulated_dw']\n",
    "    current_step_accumulated_ds = model_state['step_accumulated_ds']\n",
    "\n",
    "    w_beta, w_gamma, w_delta = agent_w\n",
    "\n",
    "    #### original notes\n",
    "    # for now, i am leaving in quite a bit of commentary.\n",
    "    # we cannot just eat sheep here. if we do, it is impossible for us to simulate the effects\n",
    "    # that are seen in the ODE. there are a number of possible workarounds, some of which i dicuss below\n",
    "\n",
    "    # wolf eats sheep based on same formula, just individualized.\n",
    "    # ds_dt = alpha * s - beta * s * w\n",
    "    # dw_dt = -gamma * w + delta * beta * s * w\n",
    "    # we are definitely going to run into a data chunkiness difference here.\n",
    "    \n",
    "    # recapitulated wolf function from the ODE\n",
    "    dw_dt = (\n",
    "        -1\n",
    "        * w_gamma # gamma\n",
    "        * 1       # this here wolf\n",
    "        + w_delta # delta\n",
    "        * w_beta # beta\n",
    "        * s       # sheep\n",
    "        * 1       # this here wolf\n",
    "        )\n",
    "\n",
    "    #### original notes\n",
    "    #  let's look at this really closely under the lens of \n",
    "    # model variables and agent variables\n",
    "\n",
    "    # we effectively need to process changes that affect other *agents*.\n",
    "    # there are two primary ways to do this:\n",
    "    # we could have a model-level variable that is basically wolf_agent_count\n",
    "    # this seems possibly effective but the problem is that technically a model-level var\n",
    "    # should only interact on agents individually\n",
    "    # in other words we would need some \"wolf pressure\" and a function.\n",
    "    # not necessarily a hack if we formally tie it back to the ODE!\n",
    "\n",
    "    # we can of course also affect other agents directly\n",
    "    # with the output from this function.\n",
    "    ####\n",
    "\n",
    "    # for now our approach is to have the model-level accumulation of changes to state.\n",
    "    # interestingly, these accumulations are intrastep, since all the wolves process at once.\n",
    "    # however, taking this approach allows us to stick to the idea that the agent itself is responsible for effecting change\n",
    "    # at the step runtime. in other words, it keeps the agent \"doing\" something.\n",
    "\n",
    "    added_dw = dw_dt * dt # scale to dt!\n",
    "    model_state['step_accumulated_dw'] = added_dw + current_step_accumulated_dw\n",
    "\n",
    "    # calculate the change in sheep using ONLY the contibution from THIS wolf\n",
    "\n",
    "    ds_dt_one_w_only = - w_beta * s\n",
    "    model_state['step_accumulated_ds'] = ds_dt_one_w_only * dt + current_step_accumulated_ds\n",
    "\n",
    "    return model_state\n",
    "    \n",
    "#################################################################\n",
    "# Model Functions\n",
    "#################################################################\n",
    "# Make all w_start wolves\n",
    "def initialize_agents_w(w_start):\n",
    "    agents_w = []\n",
    "    for i in range(w_start):\n",
    "        agents_w.append(instanitate_agent_w(model_params))\n",
    "    return agents_w\n",
    "\n",
    "def reset_accumulators(model_state, t):\n",
    "    model_state['step_accumulated_dw'] = 0\n",
    "    model_state['step_accumulated_ds'] = 0\n",
    "    return model_state\n",
    "\n",
    "def process_agents_step(model_params, model_state, t):\n",
    "    # this function will process all agents sychronously and return the new state of the model\n",
    "    agents_w = model_state['agents_w_state']\n",
    "    for agent_w in agents_w:\n",
    "        model_state = process_agent_step_w(agent_w, model_params, model_state)\n",
    "\n",
    "    return model_state\n",
    "\n",
    "def ODE_accumulate_and_fit(model_state, t): # TODO think about this name\n",
    "    # this function will need some attention, but the primary goal here is to accumulate the actions of individual agents\n",
    "    # and then use them to create a smoother model-wide change.\n",
    "    # there is a TON of formalism needed here, i believe\n",
    "    ds_total = model_state['step_accumulated_ds']\n",
    "    dw_total = model_state['step_accumulated_dw']\n",
    "    accumulated_dw_remainder = model_state['accumulated_dw_remainder']\n",
    "\n",
    "    # Apply ds_total to sheep\n",
    "    s_candidate = model_state['s_state'] + ds_total\n",
    "    s_candidate = max(0, s_candidate)  # no negative sheep\n",
    "    model_state['s_state'] = s_candidate\n",
    "\n",
    "    print_if_throttle(\"starting to process wolves\", t)\n",
    "    print_if_throttle(f\"dw_total: {dw_total}\", t)\n",
    "    # Convert dw_total to integer wolf births/deaths\n",
    "    agents_w = model_state['agents_w_state']\n",
    "    print_if_throttle(f\"agents_w: (len: {len(agents_w)})\", t)\n",
    "    # compute the step change but save the remainder\n",
    "    net_agents_w_change = int(dw_total) \n",
    "    print_if_throttle(f\"net_agents_w_change: {net_agents_w_change}\", t)\n",
    "    accumulated_dw_remainder = dw_total - net_agents_w_change\n",
    "    print_if_throttle(f\"accumulated_dw_remainder: {accumulated_dw_remainder}\", t)\n",
    "    # still need to move rounding chunks into remainder bins\n",
    "    if net_agents_w_change > 0:\n",
    "        for _ in range(net_agents_w_change):\n",
    "            agents_w.append(instanitate_agent_w(model_params))\n",
    "    elif net_agents_w_change < 0:\n",
    "        # remove that many wolves from the end\n",
    "        remove_count = min(len(agents_w), abs(net_agents_w_change))\n",
    "        for _ in range(remove_count):\n",
    "            agents_w.pop()\n",
    "\n",
    "    model_state['agents_w_state'] = agents_w\n",
    "    print_if_throttle(f\"agents_w_state updated: (len: {len(agents_w)})\", t)\n",
    "\n",
    "    # Optional correction (eps)\n",
    "\n",
    "    # eps = model_params.get('eps', 0.0)\n",
    "    # TODO, this would be an upportunity to push off of zeros\n",
    "    # e.g. model_state['s_state'] = un_zero() ...\n",
    "\n",
    "    return model_state\n",
    "\n",
    "def process_s_euler_forward(model_params, model_state, t):\n",
    "    # unpack\n",
    "    alpha = model_params['alpha']\n",
    "    s = model_state['s_state']\n",
    "    # this model function operates on the model-level population of sheep, and model variables for sheep\n",
    "    ds_dt = (\n",
    "        (\n",
    "            alpha    # model, not agent, variable; operates population-wide   \n",
    "            * s        # sheep count\n",
    "        )\n",
    "    )\n",
    "    # send value with which to update model_level sheep variable\n",
    "    # don't go below zero\n",
    "    new_s = max(0, s + ds_dt * model_params['dt'])\n",
    "    model_state['s_state'] = new_s\n",
    "    return model_state\n",
    "\n",
    "def process_model_step(model_params, model_state, t):\n",
    "    # agents move first, arbitrary\n",
    "    model_state = reset_accumulators(model_state, t)\n",
    "    model_state = process_agents_step(model_params, model_state, t)\n",
    "    model_state = ODE_accumulate_and_fit(model_state, t)\n",
    "    model_state = process_s_euler_forward(model_params, model_state, t)\n",
    "    return model_state\n",
    "\n",
    "#################################################################\n",
    "# Utility Functions\n",
    "#################################################################\n",
    "\n",
    "# for reference ODE only\n",
    "def dx_dt(x, t, alpha, beta, gamma, delta):\n",
    "    s, w = x\n",
    "    ds_dt = alpha * s - beta * s * w\n",
    "    dw_dt = -gamma * w + delta * beta * s * w\n",
    "    return [ds_dt, dw_dt]\n",
    "\n",
    "def get_reference_ODE(model_params, model_time):\n",
    "    alpha = model_params['alpha']\n",
    "    beta = model_params['beta']\n",
    "    gamma = model_params['gamma']\n",
    "    delta = model_params['delta']\n",
    "    \n",
    "    t_end = model_time['time']\n",
    "    dt    = model_params['dt']\n",
    "    times = np.linspace(0, t_end, model_time['tmax'])\n",
    "\n",
    "    # initial conditions\n",
    "    x0 = [model_params['s_start'], model_params['w_start']]\n",
    "\n",
    "    # solve\n",
    "    integration = odeint(dx_dt, x0, times, args=(alpha, beta, gamma, delta)) # via cursor, verify this\n",
    "    # Convert to DataFrame\n",
    "    ode_df = pd.DataFrame({\n",
    "        't': times,\n",
    "        's': integration[:,0],\n",
    "        'w': integration[:,1]\n",
    "    })\n",
    "    return ode_df\n",
    "\n",
    "def print_if_throttle(stmt, t):\n",
    "    # Print all statements for t < 10\n",
    "    if t < 10:\n",
    "        print(stmt)\n",
    "        return\n",
    "        \n",
    "    # For t >= 10, only print when t is a power of 10\n",
    "    log10_t = int(np.log10(t))\n",
    "    if t % (10 ** log10_t) == 0:\n",
    "        print(stmt)\n",
    "    return\n",
    "#################################################################\n",
    "# The Model\n",
    "#################################################################   \n",
    "\n",
    "# Simulate with wolves\n",
    "def run_agent_based_model(model_params, model_state, model_time):\n",
    "    # model implementation of time\n",
    "    model_time['time'] = model_time['tmax'] * model_params['dt']\n",
    "\n",
    "    # unpack model params\n",
    "    model_state = {\n",
    "        's_state': model_params['s_start'],\n",
    "        'agents_w_state': initialize_agents_w(model_params['w_start']),\n",
    "        'step_accumulated_dw': 0,\n",
    "        'step_accumulated_ds': 0,\n",
    "        'accumulated_dw_remainder': 0\n",
    "    }\n",
    "    # unpack dt\n",
    "    dt = model_params['dt']\n",
    "\n",
    "    print(f\"initialized model_states with {model_state['s_state']} sheep and {len(model_state['agents_w_state'])} wolves\")\n",
    "    # the stores record model functioning over time. initialize them using model state.\n",
    "    # individual stores since one contains lists.\n",
    "    s_store = [model_params['s_start']]\n",
    "    agents_w_store = []\n",
    "    agents_w_store = [model_state['agents_w_state'][:]]  # Shallow copy is fine for immutable tuples\n",
    "    t_store = [0]\n",
    "\n",
    "    print(f\"initialized stores with {s_store} sheep and (len: {len(agents_w_store)}) wolves\")\n",
    "\n",
    "    # reference ODE. for now we just put it in memory.\n",
    "    reference_ODE = get_reference_ODE(model_params, model_time)\n",
    "\n",
    "    # iterate over steps\n",
    "    for t in range(model_time['tmax']):\n",
    "        print_if_throttle(f'step {t}', t)\n",
    "        print_if_throttle(f's: {model_state[\"s_state\"]}', t)\n",
    "        print_if_throttle(f'agents_w count: {len(model_state[\"agents_w_state\"])}', t)\n",
    "\n",
    "        # process model step\n",
    "        # note that our model processing doesn't need the step number; just dt\n",
    "        model_state = process_model_step(model_params, model_state, t)\n",
    "    \n",
    "        # make a record in the stores\n",
    "        s_store.append(model_state['s_state'])\n",
    "        agents_w_store.append(model_state['agents_w_state'][:])  # Store a copy of the current agents list\n",
    "        t_store.append(t_store[-1] + dt)\n",
    "\n",
    "        # print the appropriate timepoint from the reference ODE\n",
    "        print_if_throttle(f\"reference ODE: {reference_ODE.loc[t, ['s', 'w']]}\", t)\n",
    "\n",
    "    # Generate a model return\n",
    "    xdf = pd.DataFrame({\n",
    "        's': s_store, \n",
    "        'w': [len(agent_list) for agent_list in agents_w_store],  # Convert each list of agents to count\n",
    "        't': t_store\n",
    "    })\n",
    "\n",
    "    return xdf\n",
    "\n",
    "#################################################################\n",
    "# Notebook Work\n",
    "#################################################################\n",
    "\n",
    "# Run the model\n",
    "xdf = run_agent_based_model(model_params, model_state, model_time)\n",
    "\n",
    "# Plot the stabilized system\n",
    "sns.lineplot(pd.melt(xdf, id_vars=['t']), x = 't', y = 'value', hue = 'variable', palette=['cadetblue', 'darkred'])\n",
    "plt.legend(frameon = False, ncol = 2, loc='lower center', bbox_to_anchor=(.5, -.2))\n",
    "sns.despine(left = True, bottom = True)\n",
    "plt.subplots_adjust(bottom=0.2)\n",
    "#plt.savefig('hungry-like-an-agent_LVtimeseries.pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
